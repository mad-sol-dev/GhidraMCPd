![ghidra\_MCP\_logo](images/ghidraMCPd.png)

# GhidraMCPd ‚Äì token-efficient MCP server for Ghidra

Deterministic MCP server for the Ghidra plugin, focused on lowering token spend while keeping response schemas stable and auditable.

> **‚ö†Ô∏è AI-Generated Code:** This repository's code is almost entirely generated by AI assistants (Codex, AiderDesk). Human role: architecture, planning, review, testing, and documentation. Use at your own risk.
>
> **Status:** Experimental ‚Ä¢ **License:** Apache 2.0
> **Credit:** Fork of **GhidraMCP** ‚Äì thanks to **Laurie Wired** for the original project.

---

<video width="630" height="300" src="https://github.com/user-attachments/assets/03597acf-f9f3-41ec-bab3-db849367123c"></video>

## Quickstart

```bash
python -m venv .venv
source .venv/bin/activate
# install the runtime dependencies only
python -m pip install -r requirements.txt
# optionally install development/test dependencies (needed for unit and contract tests)
python -m pip install -r requirements-dev.txt
uvicorn bridge.app:create_app --factory --host 127.0.0.1 --port 8000
```

Once running, open Ghidra with a project and the server will connect automatically.

### Legacy / stdio mode

Need a console-first workflow or migrating from the original bridge helper? Run the
legacy entry point instead of Uvicorn:

```bash
python scripts/bridge_stdio.py --transport stdio
```

This launches the MCP server directly over stdio (no `/sse` endpoint or OpenWebUI
shim). Use it when testing locally without a browser client or when you need to
mimic the pre-shim behavior. SSE mode is recommended for modern clients.

---

## Motivation

Started as a side-quest while building an e-recumbent bike battery (needed to label matched cells ‚Üí bought a Chinese handheld HP45 printer ‚Üí found SD card ‚Üí firmware RE ‚Üí here we are üö¥).

Bridging Ghidra through MCP can be API-expensive when clients emit many small calls. Each call has a fixed overhead (request envelope, auth, JSON schemas, response framing), so dozens of tiny round-trips quickly blow up token usage.

GhidraMCPd reduces this by:

* favoring **fewer, coarse-grained calls** instead of many tiny ones
* doing more **context assembly on the server side**
* enforcing **deterministic, compact response shapes** that are easy to diff and cache

How much you save depends on your workflow, but batching and server-side context usually cut round-trips and JSON noise significantly.

---

## Highlights

* **Batch operations**
  `disassemble_batch`, `read_words`, and the `collect` endpoint let you work on many addresses / ranges in a single request.

* **Contextual search**
  `search_scalars_with_context` returns matches plus a server-side disassembly window around them, so clients don't need extra ‚Äúgive me the surrounding instructions‚Äù calls.

* **Deterministic pagination**
  Resume-friendly cursors with fixed limits; totals stay stable when determinable so clients can page reliably.

* **Strict envelopes & schemas**
  All responses use a `{ ok, data, errors[] }` envelope with `additionalProperties:false`, making them LLM-friendly and easy to diff/audit.

* **Guard rails for writes**
  Write operations are disabled by default (`ENABLE_WRITES`, `dry_run`), with safety limits and observability exposed via `/state`.

* **Tested for drift**
  Contract, golden (OpenAPI/HTTP parity), and unit tests keep implementation and spec aligned over time.

---

## MCP client examples

Theoretically, any MCP client should work with GhidraMCPd.

### AiderDesk
Example configuration for AiderDesk: go to `Settings` ‚Üí `Agent` ‚Üí `MCP Servers (Agent Settings)` ‚Üí `Add` / `Edit Config` and add:

```json
{
  "mcpServers": {
    "ghidra-bridge": {
      "name": "Ghidra Bridge",
      "type": "sse",
      "url": "http://127.0.0.1:8000/sse"
    }
  }
}
```
### Codex

Add to /home/user/.codex/config.toml

```bash
[mcp_servers.ghidra-bridge]
# ganz konkret den venv-Python verwenden
command = "/your/path/to/GhidraMCPd/.venv/bin/python"

# Script relativ zum Repo-Root, daher cwd setzen
args = ["scripts/bridge_stdio.py", "--transport", "stdio"]

# wichtig, damit relative Pfade im Server stimmen
cwd = "/your/path/to/GhidraMCPd"
```

For more MCP client examples, see [docs/getting-started.md](docs/getting-started.md).

---

## Example usage

```bash
# Find all functions using MMIO address 0x40000000
curl -X POST http://localhost:8000/api/collect.json \
  -H 'content-type: application/json' \
  -d '{
        "queries": [
          {
            "id": "mmio-usages",
            "op": "search_scalars_with_context",
            "params": {"value": "0x40000000", "context_lines": 2, "limit": 10}
          }
        ]
      }'

# Analyze function with decompiler
curl -X POST http://localhost:8000/api/analyze_function_complete.json \
  -H 'content-type: application/json' \
  -d '{"address":"0x1000","fields":["function","decompile","xrefs"]}'
```

For more examples, see [docs/api.md](docs/api.md).

---

## Build the Ghidra extension

Populate `lib/` with the required Ghidra jars, then run Maven:

```bash
python scripts/fetch_ghidra_jars.py
mvn -DskipTests package
```

If you already have a local Ghidra checkout, you can still point Maven at it directly:

```bash
export GHIDRA_DIR=/path/to/ghidra_*_PUBLIC && mvn -DskipTests package
```

The build produces `target/GhidraMCP-1.0-SNAPSHOT.jar`.

**Installation:**

1. Copy the JAR to Ghidra's Extensions directory:

   ```bash
   cp target/GhidraMCP-1.0-SNAPSHOT.jar $GHIDRA_INSTALL_DIR/Extensions/Ghidra/
   ```

   Or use Ghidra's GUI: **File ‚Üí Install Extensions** and select the JAR file.

2. Restart Ghidra to load the extension.

3. **Activate:** After restarting, go to **File ‚Üí Configure ‚Üí Developer/Configure**. Find `GhidraMCP` in the list (usually under the "Analysis" category) and **check the box** next to it to enable it. The plugin will not be active until you do this.

---

## API overview

For the full list of endpoints and request/response schemas, see [docs/api.md](docs/api.md).

Key categories:

* **Batch & aggregation** ‚Äì `/api/collect.json`
* **Search & analysis** ‚Äì `search_*`, `string_xrefs`, `list_functions_in_range`, etc.
* **Memory & disassembly** ‚Äì `read_*`, `disassemble_*`
* **Advanced analysis** ‚Äì `analyze_function_complete`, jump-table helpers
* **Data & utilities** ‚Äì `strings_compact`, `project_*`, `write_bytes`, `health`

---

## Documentation

* [Getting started](docs/getting-started.md) ‚Äì Installation and configuration
* [Server operations](docs/server.md) ‚Äì Running and managing the server (SSE vs stdio, `/state`, readiness, etc.)
* [API reference](docs/api.md) ‚Äì Endpoints, payloads, and examples
* [Troubleshooting](docs/troubleshooting.md) ‚Äì Common issues and solutions
* [Development workflow](docs/development.md) ‚Äì Contributing and `.plan/` process

---

## Status

This repo is maintained with a deterministic plan. See [Development workflow](docs/development.md) for the `.plan/` process.

## Contributing

Contributions welcome! This is an experimental project with AI-generated code ‚Äì review carefully and test thoroughly. See [Development workflow](docs/development.md) for the `.plan/` process.

## License

Apache 2.0 ‚Äì See [LICENSE](LICENSE) for details.
